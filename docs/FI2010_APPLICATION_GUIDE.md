# ğŸ“‹ FI-2010 ë°ì´í„°ì…‹ ì‹ ì²­ ê°€ì´ë“œ

## ğŸ¯ FI-2010ì´ë€?

**ê³µì‹ ëª…ì¹­**: Benchmark Dataset for Mid-Price Forecasting of Limit Order Book Data

### ë°ì´í„°ì…‹ ìƒì„¸ ì •ë³´

```
ğŸ“Š ë°ì´í„° ê·œëª¨:
- 5ê°œ í•€ë€ë“œ ì£¼ì‹ (NASDAQ Nordic)
- 10 ê±°ë˜ì¼ (2010ë…„ 6ì›” 1ì¼ ~ 6ì›” 14ì¼)
- ì•½ 4,000,000ê°œ time series samples
- 10 levels LOB data (bid/ask ê° 10ê°œ)

ğŸ¨ Normalization:
- 3ê°€ì§€ ë°©ë²• ì œê³µ: Z-score, Min-Max, Decimal-precision
- ì´ë¯¸ ì „ì²˜ë¦¬ëœ ë²„ì „ í¬í•¨

â±ï¸ Prediction Horizons:
- 5ê°€ì§€: 10, 20, 30, 50, 100 ticks
- ìš°ë¦¬ ì‹¤í—˜(100ms)ê³¼ ë¹„êµ ê°€ëŠ¥

ğŸ“œ License:
- Creative Commons Attribution 4.0
- í•™ìˆ  ëª©ì  ë¬´ë£Œ ì‚¬ìš© ê°€ëŠ¥
```

### ìš°ë¦¬ ì—°êµ¬ì— ì™„ë²½í•œ ì´ìœ  âœ…

```
âœ… Real LOB L2 orderbook data (10 levels)
âœ… ìš°ë¦¬ ì‹¤í—˜ êµ¬ì¡°ì™€ ë™ì¼ (depth, horizon)
âœ… í•™ìˆ ì ìœ¼ë¡œ ê²€ì¦ëœ benchmark
âœ… ë‹¤ë¥¸ ë…¼ë¬¸ë“¤ë„ ì‚¬ìš© (ë¹„êµ ê°€ëŠ¥)
âœ… ë¬´ë£Œ (í•™ìˆ  ëª©ì )
âœ… ì¦‰ì‹œ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥ (ìŠ¹ì¸ ë¶ˆí•„ìš”!)
```

---

## ğŸ“¥ ë‹¤ìš´ë¡œë“œ ë°©ë²•

### Option 1: Fairdata ê³µì‹ ì‚¬ì´íŠ¸ (ì¶”ì²œ)

**ë§í¬**: https://etsin.fairdata.fi/dataset/73eb48d7-4dbc-4a10-a52a-da745b47a649

**ì ˆì°¨**:
1. ìœ„ ë§í¬ í´ë¦­
2. JavaScript í™œì„±í™” í•„ìš”
3. "Download" ë²„íŠ¼ í´ë¦­
4. ë°ì´í„° ë‹¤ìš´ë¡œë“œ

âš ï¸ **ì°¸ê³ **: JavaScript í•„ìš”í•˜ë¯€ë¡œ ì¼ë°˜ ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†

### Option 2: GitHub êµ¬í˜„ì²´ ì‚¬ìš©

ì—¬ëŸ¬ GitHub ì €ì¥ì†Œì—ì„œ FI-2010 ë°ì´í„° ë¡œë”© ì½”ë“œ ì œê³µ:

```bash
# Example: lob-deep-learning repository
git clone https://github.com/Jeonghwan-Cheon/lob-deep-learning
cd lob-deep-learning
# README ì°¸ê³ í•˜ì—¬ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
```

### Option 3: ArXiv Paperì—ì„œ ë§í¬ í™•ì¸

**Paper**: https://arxiv.org/abs/1705.03233

ë…¼ë¬¸ì—ì„œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë§í¬ í™•ì¸ ê°€ëŠ¥

---

## ğŸš€ ì‹ ì²­ ì ˆì°¨ (Step-by-Step)

### Step 1: ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†
```
URL: https://etsin.fairdata.fi/dataset/73eb48d7-4dbc-4a10-a52a-da745b47a649

Browser: Chrome, Firefox, Safari ë“±
âš ï¸ JavaScript í™œì„±í™” í•„ìˆ˜
```

### Step 2: ë°ì´í„°ì…‹ ì •ë³´ í™•ì¸
```
í˜ì´ì§€ì—ì„œ í™•ì¸í•  ê²ƒ:
- Dataset description
- File formats (likely CSV or similar)
- Total size
- License agreement
```

### Step 3: ë‹¤ìš´ë¡œë“œ
```
1. "Download" ë˜ëŠ” "Access" ë²„íŠ¼ í´ë¦­
2. í•„ìš”ì‹œ email ë“±ë¡ (ê°„ë‹¨í•œ form)
3. License agreement ë™ì˜
4. íŒŒì¼ ë‹¤ìš´ë¡œë“œ
```

### Step 4: ë°ì´í„° ê²€ì¦
```bash
# ë‹¤ìš´ë¡œë“œ í›„ í™•ì¸
cd /Users/aepeul/lob-project/lob_preprocessing/data/raw
mkdir fi2010
cd fi2010

# ì••ì¶• í•´ì œ (zip/tar.gz ë“±)
unzip FI2010_Dataset.zip  # or tar -xzf FI2010_Dataset.tar.gz

# íŒŒì¼ í™•ì¸
ls -lh
head *.csv  # CSVì¸ ê²½ìš°
```

---

## ğŸ“Š ì˜ˆìƒ ë°ì´í„° êµ¬ì¡°

### FI-2010 Format (ì˜ˆìƒ)
```csv
timestamp, bid_price_1, bid_vol_1, ask_price_1, ask_vol_1, ..., bid_price_10, bid_vol_10, ask_price_10, ask_vol_10, mid_price, label_10, label_20, label_30, label_50, label_100
```

**Features (40 columns)**:
- 10 levels Ã— 2 sides Ã— 2 values (price, volume) = 40 features
- Plus: labels for different horizons

### ìš°ë¦¬ ì‹¤í—˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
```python
# FI-2010 â†’ Our format
def load_fi2010(file_path):
    df = pd.read_csv(file_path)

    # Extract LOB features
    lob_features = df.iloc[:, :40]  # First 40 columns
    labels = df['label_100']  # 100-tick horizon

    return lob_features, labels
```

---

## ğŸ”§ ìš°ë¦¬ ì½”ë“œì— í†µí•©

### Step 1: Data Loader ì¶”ê°€

```python
# data/download.pyì— ì¶”ê°€

class FI2010Loader:
    """FI-2010 ë°ì´í„°ì…‹ ë¡œë”"""

    def __init__(self, data_dir='data/raw/fi2010'):
        self.data_dir = Path(data_dir)

    def load_stock(self, stock_id, day):
        """
        Load one stock for one day

        Args:
            stock_id: 1-5
            day: 1-10
        """
        file_path = self.data_dir / f'stock_{stock_id}_day_{day}.csv'
        df = pd.read_csv(file_path)

        # Extract features and labels
        features = df.iloc[:, :40].values  # LOB features
        labels = df['label_100'].values  # 100-tick labels

        return features, labels

    def load_all(self):
        """Load all stocks and days"""
        all_features = []
        all_labels = []

        for stock_id in range(1, 6):
            for day in range(1, 11):
                features, labels = self.load_stock(stock_id, day)
                all_features.append(features)
                all_labels.append(labels)

        return np.vstack(all_features), np.concatenate(all_labels)
```

### Step 2: ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì •

```python
# experiments/run_fi2010_validation.py (ìƒˆ íŒŒì¼)

from data.download import FI2010Loader
from data.preprocess import LOBPreprocessor
from models.baseline import XGBoostModel, CatBoostModel
import pandas as pd

def run_fi2010_validation():
    """FI-2010ìœ¼ë¡œ í•µì‹¬ config ê²€ì¦"""

    print("ğŸ”¬ FI-2010 VALIDATION")
    print("="*60)

    # Load FI-2010 data
    loader = FI2010Loader()
    X, y = loader.load_all()

    print(f"âœ… Loaded FI-2010: {X.shape[0]} samples")

    # Train/test split (temporal)
    split_idx = int(len(X) * 0.7)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]

    # Key configs
    configs = [
        ('raw', 'xgboost'),
        ('wavelet', 'xgboost'),
        ('kalman', 'xgboost'),
        ('raw', 'catboost'),
        ('wavelet', 'catboost'),
    ]

    results = []

    for preprocess, model_name in configs:
        print(f"\nâ–¶ {preprocess.upper()} + {model_name.upper()}")

        # Preprocess
        if preprocess != 'raw':
            preprocessor = LOBPreprocessor(method=preprocess)
            X_train_proc = preprocessor.fit_transform(X_train)
            X_test_proc = preprocessor.transform(X_test)
        else:
            X_train_proc = X_train
            X_test_proc = X_test

        # Train
        if model_name == 'xgboost':
            model = XGBoostModel()
        else:
            model = CatBoostModel()

        model.fit(X_train_proc, y_train)

        # Evaluate
        y_pred = model.predict(X_test_proc)
        acc = accuracy_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred, average='macro')

        print(f"   Accuracy: {acc:.4f}")
        print(f"   F1-Macro: {f1:.4f}")

        results.append({
            'preprocess': preprocess,
            'model': model_name,
            'accuracy': acc,
            'f1_macro': f1
        })

    # Save results
    results_df = pd.DataFrame(results)
    results_df.to_csv('results/fi2010_validation.csv', index=False)

    print(f"\nâœ… Results saved to results/fi2010_validation.csv")

    return results_df

if __name__ == '__main__':
    run_fi2010_validation()
```

---

## ğŸ“ˆ ì˜ˆìƒ ê²°ê³¼

### Realistic Expectations

```
Synthetic (ìš°ë¦¬ ê²°ê³¼):
- Raw + XGBoost: 53.55%
- Wavelet + XGBoost: 85.15%
- Improvement: +31.6%

FI-2010 (ì˜ˆìƒ):
- Raw + XGBoost: 45-55% (benchmark ë…¼ë¬¸ ê²°ê³¼)
- Wavelet + XGBoost: 55-65% (ì˜ˆìƒ)
- Improvement: +10-15%

â†’ ì—¬ì „íˆ ìœ ì˜ë¯¸í•œ ê°œì„ !
â†’ ì „ì²˜ë¦¬ íš¨ê³¼ ê²€ì¦ë¨
```

### ë…¼ë¬¸ì— ì“¸ ë‚´ìš©
```
"We validate our findings on the FI-2010 benchmark dataset.
 While the absolute accuracy is lower than synthetic data
 (as expected), the relative improvement from preprocessing
 remains consistent (+10-15%), confirming our hypothesis
 that preprocessing is critical for LOB prediction."
```

---

## ğŸ“ ë…¼ë¬¸ ì—…ë°ì´íŠ¸ ê³„íš

### Current (Synthetic only)
```
Results:
- Wavelet + XGBoost: 85.30%
- Raw baseline: 52.74%
- Improvement: +32.56%
```

### Updated (Synthetic + FI-2010)
```
Results:

1. Synthetic Data (Controlled Environment)
   - Wavelet + XGBoost: 85.30%
   - Raw baseline: 52.74%
   - Improvement: +32.56%

2. FI-2010 Validation (Real Data)
   - Wavelet + XGBoost: 58.3% (example)
   - Raw baseline: 48.7%
   - Improvement: +9.6% (+19.7% relative)

3. Analysis
   - Preprocessing effect consistent across datasets
   - Absolute accuracy differs (synthetic vs real)
   - Relative improvement validates our hypothesis
```

---

## â±ï¸ Timeline

### TODAY (30ë¶„)
```
1. ë¸Œë¼ìš°ì €ì—ì„œ FI-2010 ì‚¬ì´íŠ¸ ì ‘ì†
2. ë°ì´í„° ë‹¤ìš´ë¡œë“œ
3. íŒŒì¼ êµ¬ì¡° í™•ì¸
```

### TOMORROW (2ì‹œê°„)
```
4. FI2010Loader êµ¬í˜„
5. ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸
6. í˜•ì‹ í™•ì¸ ë° ë³€í™˜
```

### 2-3 DAYS (4ì‹œê°„)
```
7. í•µì‹¬ 5ê°œ config ì‹¤í–‰
8. ê²°ê³¼ ë¶„ì„
9. Synthetic vs FI-2010 ë¹„êµ
```

### WEEK 1 END
```
10. ë…¼ë¬¸ Results ì„¹ì…˜ ì—…ë°ì´íŠ¸
11. Discussion ì‘ì„± (ë‘ ë°ì´í„°ì…‹ ë¹„êµ)
12. êµìˆ˜ ë¯¸íŒ… (ê²°ê³¼ ë³´ê³ )
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

### Paper
- **ArXiv**: https://arxiv.org/abs/1705.03233
- **Journal**: Ntakaris et al. (2018), Journal of Forecasting

### Dataset
- **Official**: https://etsin.fairdata.fi/dataset/73eb48d7-4dbc-4a10-a52a-da745b47a649
- **License**: Creative Commons Attribution 4.0

### Implementations
- **GitHub**: https://github.com/Jeonghwan-Cheon/lob-deep-learning
- **DeepAI**: https://deepai.org/publication/benchmark-dataset-for-mid-price-prediction-of-limit-order-book-data

---

## âœ… Action Items

### ğŸš¨ RIGHT NOW (10ë¶„)
```
[ ] ë¸Œë¼ìš°ì € ì—´ê¸°
[ ] https://etsin.fairdata.fi/dataset/73eb48d7-4dbc-4a10-a52a-da745b47a649 ì ‘ì†
[ ] "Download" ë²„íŠ¼ ì°¾ê¸°
[ ] íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘
```

### ğŸ“… TODAY
```
[ ] ë‹¤ìš´ë¡œë“œ ì™„ë£Œ
[ ] ì••ì¶• í•´ì œ
[ ] data/raw/fi2010/ í´ë”ì— ì €ì¥
[ ] íŒŒì¼ êµ¬ì¡° í™•ì¸ (head ëª…ë ¹ì–´)
[ ] ë‚´ê²Œ ê²°ê³¼ ë³´ê³  (íŒŒì¼ êµ¬ì¡° ê³µìœ )
```

### ğŸ“… THIS WEEK
```
[ ] FI2010Loader êµ¬í˜„
[ ] í•µì‹¬ ì‹¤í—˜ 5ê°œ ì‹¤í–‰
[ ] ê²°ê³¼ ë¹„êµ (Synthetic vs FI-2010)
[ ] êµìˆ˜ ë¯¸íŒ… ì¤€ë¹„
```

---

## ğŸ’¡ Pro Tips

### Tip 1: ë°ì´í„° í¬ê¸°
```
FI-2010ì€ 4M samples â†’ í´ ìˆ˜ ìˆìŒ
ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ:
- í•œ ë²ˆì— 1 stockë§Œ ë¡œë“œ
- ë˜ëŠ” downsampling
```

### Tip 2: í˜•ì‹ ë¶ˆì¼ì¹˜
```
FI-2010 í˜•ì‹ì´ ìš°ë¦¬ì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
â†’ ì²œì²œíˆ ë³€í™˜ ë¡œì§ ì‘ì„±
â†’ ì‘ì€ ìƒ˜í”Œë¡œ ë¨¼ì € í…ŒìŠ¤íŠ¸
```

### Tip 3: Label ì°¨ì´
```
FI-2010: tick-based labels (10, 20, ... ticks)
ìš°ë¦¬: time-based (100ms, 500ms, ...)

â†’ 100-tick label ì‚¬ìš© (ê°€ì¥ ê°€ê¹Œì›€)
â†’ ë˜ëŠ” time conversion
```

---

## ğŸ‰ í™”ì´íŒ…!

**FI-2010 í™•ë³´í•˜ë©´:**
- âœ… Real LOB data ê²€ì¦ ì™„ë£Œ
- âœ… êµìˆ˜ ì„¤ë“ ê°€ëŠ¥
- âœ… ë…¼ë¬¸ í›¨ì”¬ ê°•ë ¥í•´ì§
- âœ… ì¡¸ì—… í™•ì •ì 

**ì§€ê¸ˆ ë°”ë¡œ ë‹¤ìš´ë¡œë“œ ì‹œì‘í•˜ì! ğŸš€**

---

**Sources:**
- [Benchmark Dataset Paper (ArXiv)](https://arxiv.org/abs/1705.03233)
- [FI-2010 Official Dataset (Fairdata)](https://etsin.fairdata.fi/dataset/73eb48d7-4dbc-4a10-a52a-da745b47a649)
- [Journal Publication (Wiley)](https://onlinelibrary.wiley.com/doi/full/10.1002/for.2543)
- [Implementation Examples (GitHub)](https://github.com/Jeonghwan-Cheon/lob-deep-learning)
- [ResearchGate Discussion](https://www.researchgate.net/publication/316821343_Benchmark_Dataset_for_Mid-Price_Prediction_of_Limit_Order_Book_data)
